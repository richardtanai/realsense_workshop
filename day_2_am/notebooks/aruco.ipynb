{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aruco Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_utils.aruco_utils import ARUCO_DICT, aruco_display\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect aruco marker in an image\n",
    "img_path = \"/home/richard/realsense_workshop/day_2_am/resources/test_image_1.png\"\n",
    "aruco_dict_type = ARUCO_DICT[\"DICT_5X5_250\"]\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# h,w,_ = img.shape\n",
    "# width=600\n",
    "# height = int(width*(h/w))\n",
    "# image = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "arucoDict = cv2.aruco.getPredefinedDictionary(aruco_dict_type)\n",
    "arucoParams = cv2.aruco.DetectorParameters()\n",
    "corners, ids, rejected = cv2.aruco.detectMarkers(img, arucoDict, parameters=arucoParams)\n",
    "\n",
    "detectedMarkers = aruco_display(corners, ids, rejected, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Aruco Window\", detectedMarkers)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aruco Markers Live Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCameraIndexes():\n",
    "    # checks the first 10 indexes.\n",
    "    index = 0\n",
    "    arr = []\n",
    "    i = 10\n",
    "    while i > 0:\n",
    "        cap = cv2.VideoCapture(index)\n",
    "        if cap.read()[0]:\n",
    "            arr.append(index)\n",
    "            cap.release()\n",
    "        index += 1\n",
    "        i -= 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returnCameraIndexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    arucoDict = cv2.aruco.getPredefinedDictionary(aruco_dict_type)\n",
    "    arucoParams = cv2.aruco.DetectorParameters()\n",
    "    corners, ids, rejected = cv2.aruco.detectMarkers(img, arucoDict, parameters=arucoParams)\n",
    "\n",
    "    detectedMarkers = aruco_display(corners, ids, rejected, img)\n",
    "\n",
    "    cv2.imshow(\"Live Capture aruco markers\", detectedMarkers)\n",
    "    \n",
    "    # process image here\n",
    "    \n",
    "    key  = cv2.waitKey(1)\n",
    "    # press q to exit\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation with Aruco Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_estimation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients, marker_size):\n",
    "\n",
    "    '''\n",
    "    frame - Frame from the video stream\n",
    "    matrix_coefficients - Intrinsic matrix of the calibrated camera\n",
    "    distortion_coefficients - Distortion coefficients associated with your camera\n",
    "\n",
    "    return:-\n",
    "    frame - The frame with the axis drawn on it\n",
    "    '''\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # aruco_dict = cv2.aruco.Dictionary_get(aruco_dict_type)\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(aruco_dict_type)\n",
    "    \n",
    "    # parameters = cv2.aruco.DetectorParameters_create()\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "\n",
    "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, aruco_dict,parameters=parameters)\n",
    "\n",
    "        # If markers are detected\n",
    "    res = {}\n",
    "\n",
    "\n",
    "    if len(corners) > 0:\n",
    "        for i in range(0, len(ids)):\n",
    "            # Estimate pose of each marker and return the values rvec and tvec---(different from those of camera coefficients)\n",
    "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], marker_size, matrix_coefficients,\n",
    "                                                                       distortion_coefficients)\n",
    "            # Draw a square around the markers\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners) \n",
    "\n",
    "            # Draw Axis\n",
    "            cv2.drawFrameAxes(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.01)\n",
    "\n",
    "            temp = {}\n",
    "            temp[\"tvec\"] = tvec\n",
    "            temp[\"rvec\"] = rvec\n",
    "            temp[\"marker\"] = markerPoints\n",
    "\n",
    "            res[int(ids[i][0])] = temp\n",
    "\n",
    "    return frame, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load camera params\n",
    "\n",
    "k = np.load(\"calibration_matrix.npy\")\n",
    "d = np.load(\"distortion_coefficients.npy\")\n",
    "\n",
    "aruco_dict_type = ARUCO_DICT[\"DICT_5X5_50\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a Picture of Two Aruco Markers\n",
    "In this example we use the marker 1 and marker 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    out_img = img.copy()\n",
    "\n",
    "    output, res = pose_estimation(img, aruco_dict_type, k, d, 0.030)\n",
    "    \n",
    "    # process image here\n",
    "    cv2.imshow('Aruco',output)\n",
    "    \n",
    "    key  = cv2.waitKey(1)\n",
    "    # press q to exit\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    if key == ord(\"c\"):\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "        cv2.imwrite(f'{now}.jpg', out_img)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# detect aruco marker in an image\n",
    "img_path = \"/home/richard/realsense_workshop/day_2_am/notebooks/2024-08-27-112839.jpg\"\n",
    "# aruco_dict_type = ARUCO_DICT[\"DICT_5X5_50\"]\n",
    "aruco_dict_type = cv2.aruco.DICT_5X5_50\n",
    "marker_size = 0.030\n",
    "\n",
    "matrix_coefficients = np.load(\"calibration_matrix.npy\")\n",
    "distortion_coefficients = np.load(\"distortion_coefficients.npy\")\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# h,w,_ = img.shape\n",
    "# width=600\n",
    "# height = int(width*(h/w))\n",
    "# image = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "arucoDict = cv2.aruco.getPredefinedDictionary(aruco_dict_type)\n",
    "arucoParams = cv2.aruco.DetectorParameters()\n",
    "corners, ids, rejected = cv2.aruco.detectMarkers(img, arucoDict, parameters=arucoParams)\n",
    "\n",
    "detectedMarkers = aruco_display(corners, ids, rejected, img)\n",
    "\n",
    "corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, arucoDict,parameters=arucoParams)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(corners) > 0:\n",
    "        for i in range(0, len(ids)):\n",
    "            # Estimate pose of each marker and return the values rvec and tvec---(different from those of camera coefficients)\n",
    "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], marker_size, matrix_coefficients,\n",
    "                                                                       distortion_coefficients)\n",
    "            # Draw a square around the markers\n",
    "            cv2.aruco.drawDetectedMarkers(img, corners) \n",
    "\n",
    "            # Draw Axis\n",
    "            cv2.drawFrameAxes(img, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.01)\n",
    "\n",
    "            temp = {}\n",
    "            temp[\"tvec\"] = tvec\n",
    "            temp[\"rvec\"] = rvec\n",
    "            temp[\"marker\"] = markerPoints\n",
    "            temp[\"corners\"] = corners[i]\n",
    "\n",
    "            res[int(ids[i][0])] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"tvec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matR, _ = cv2.Rodrigues(res[4][\"rvec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(0,len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_img_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_to_world = np.array([[1,0,0,0],\n",
    "                           [0,1,0,0],\n",
    "                           [0,0,1,0],\n",
    "                           [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for aruco marker 4\n",
    "tvec4 = res[4][\"tvec\"]\n",
    "rvec4 = res[4][\"rvec\"]\n",
    "marker4 = res[4][\"marker\"]\n",
    "corners4 = res[4][\"corners\"]\n",
    "rmat4,_ = cv2.Rodrigues(rvec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 of converting to se3 tranformation matrix\n",
    "\n",
    "T_4_c = np.eye(4,4)\n",
    "T_4_c[:3,:3], _ = cv2.Rodrigues(rvec4)\n",
    "T_4_c[:3,3] = tvec4\n",
    "\n",
    "T_4_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecs_to_se3mat(rvec,tvec):\n",
    "    T = np.eye(4,4)\n",
    "    T[:3,:3], _ = cv2.Rodrigues(rvec)\n",
    "    T[:3,3] = tvec\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_4_c = vecs_to_se3mat(rvec4,tvec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec5 = res[5][\"tvec\"]\n",
    "rvec5 = res[5][\"rvec\"]\n",
    "marker5 = res[5][\"marker\"]\n",
    "corners5 = res[5][\"corners\"]\n",
    "rmat5, _ = cv2.Rodrigues(rvec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_5_c = vecs_to_se3mat(rvec5, tvec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance of marker1 and marker5\n",
    "distance = np.linalg.norm(tvec5-tvec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Position of the Origin of Marker 5 relative to the Coordinate Frame of Marker 4\n",
    "\n",
    "# temp = T_5_c * origin\n",
    "\n",
    "temp_mat = np.matmul(T_5_c,np.array([0.0,0.0,0.0,1.0]).reshape(4,1))\n",
    "\n",
    "# T_1_c inverse * T_5_c\n",
    "\n",
    "origin5_in_marker1 = np.matmul(np.linalg.inv(T_4_c), temp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin5_in_marker1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(np.linalg.inv(T_1_c), np.matmul(T_5_c,np.array([0.0,0.0,0.0,1.0]).reshape(4,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Position of the Origin of Marker 1 in terms of the coordinate fram of marker1\n",
    "\n",
    "# temp = T_1_c * origin\n",
    "\n",
    "temp_mat = np.matmul(T_1_c,np.array([0.0,0.0,0.0,1.0]).reshape(4,1))\n",
    "\n",
    "# T_5_c inverse * temp\n",
    "\n",
    "\n",
    "origin1_in_marker5 = np.matmul(np.linalg.inv(T_5_c), temp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin1_in_marker5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Pose in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pytransform3d import rotations as pr\n",
    "from pytransform3d import transformations as pt\n",
    "import pytransform3d.camera as pc\n",
    "from pytransform3d.transform_manager import TransformManager\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "marker5_to_cam = T_5_c\n",
    "marker1_to_cam = T_4_c\n",
    "\n",
    "camera_to_world = np.eye(4,4)\n",
    "\n",
    "tm = TransformManager()\n",
    "cam2world = camera_to_world\n",
    "sensor_size = np.array([0.036, 0.024])\n",
    "intrinsic_matrix = np.array([\n",
    "    [0.05, 0, sensor_size[0] / 2.0],\n",
    "    [0, 0.05, sensor_size[1] / 2.0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "virtual_image_distance = 0.1\n",
    "tm.add_transform(\"marker5\", \"camera\", marker5_to_cam)\n",
    "tm.add_transform(\"marker1\", \"camera\", marker1_to_cam)\n",
    "# tm.add_transform(\"camera\", \"world\", camera_to_world)\n",
    "\n",
    "# ee2object = tm.get_transform(\"end-effector\", \"object\")\n",
    "ax = pt.plot_transform(A2B=cam2world, s=0.1)\n",
    "ax = tm.plot_frames_in(\"camera\", s=0.1)\n",
    "ax.set_xlim((-0.10, 0.10))\n",
    "ax.set_ylim((-0.10, 0.10))\n",
    "pc.plot_camera(ax, cam2world=cam2world, M=intrinsic_matrix, sensor_size=sensor_size,\n",
    "virtual_image_distance=virtual_image_distance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
