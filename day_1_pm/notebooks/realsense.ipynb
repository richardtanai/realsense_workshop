{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First import library\n",
    "import pyrealsense2 as rs\n",
    "# Import Numpy for easy array manipulation\n",
    "import numpy as np\n",
    "# Import OpenCV for easy image rendering\n",
    "import cv2\n",
    "# Import argparse for command-line options\n",
    "import argparse\n",
    "# Import os.path for file path manipulation\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Using Realsense Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "#  different resolutions of color and depth streams\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "        \n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# the depth scale is the multiplier to the number that the \n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Using .BAG File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define path to bag\n",
    "bag_path = '/home/richard/realsense_workshop/day_1_pm/resources/desk_bgr8_f15.bag'\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# Create a config object\n",
    "config = rs.config()\n",
    "# Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "rs.config.enable_device_from_file(config, bag_path)\n",
    "\n",
    "# pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "# pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "# Configure the pipeline to stream the depth stream\n",
    "# Change this parameters according to the recorded bag file resolution\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "\n",
    "# pipeline would not resolve if the config does not match or if the config is not possible\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# the depth scale is the multiplier to the number that the \n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Create opencv window to render image in\n",
    "\n",
    "# Create colorizer object\n",
    "colorizer = rs.colorizer()\n",
    "\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "pc = rs.pointcloud()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pipeline.wait_for_frames()\n",
    "# frames.get_depth_frame() is a 640x360 depth image\n",
    "\n",
    "# Align the depth frame to color frame\n",
    "aligned_frames = align.process(frames)\n",
    "\n",
    "# Get aligned frames\n",
    "aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "# Validate that both frames are valid\n",
    "if not aligned_depth_frame or not color_frame:\n",
    "    pass\n",
    "\n",
    "depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "depth_intrinsics = rs.video_stream_profile(aligned_depth_frame.profile).get_intrinsics()\n",
    "\n",
    "depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "points = pc.calculate(aligned_depth_frame)\n",
    "pc.map_to(color_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = points.get_vertices(), points.get_texture_coordinates()\n",
    "verts = np.asanyarray(v).view(np.float32).reshape(480, 640, 3)  # xyz\n",
    "texcoords = np.asanyarray(t).view(np.float32).reshape(480, 640, 2)  # uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texcoords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_image_rgb = cv2.cvtColor(color_image,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(color_image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image_rgb = cv2.cvtColor(depth_colormap,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(depth_image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the camera\n",
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
