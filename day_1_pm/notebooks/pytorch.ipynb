{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "## define path to bag\n",
    "bag_path = '/home/richard/realsense_workshop/day_1_pm/resources/table2.bag'\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# Create a config object\n",
    "config = rs.config()\n",
    "# Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "rs.config.enable_device_from_file(config, bag_path)\n",
    "\n",
    "# pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "# pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "# Configure the pipeline to stream the depth stream\n",
    "# Change this parameters according to the recorded bag file resolution\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "\n",
    "# pipeline would not resolve if the config does not match or if the config is not possible\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# depth_profile = profile.get_stream(rs.stream.depth)\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "intr = depth_profile.get_intrinsics()\n",
    "# the depth scale is the multiplier to the number that the \n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Create opencv window to render image in\n",
    "\n",
    "# Create colorizer object\n",
    "colorizer = rs.colorizer()\n",
    "\n",
    "pc = rs.pointcloud()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_bounding_box():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pipeline.wait_for_frames()\n",
    "# frames.get_depth_frame() is a 640x360 depth image\n",
    "\n",
    "# Align the depth frame to color frame\n",
    "aligned_frames = align.process(frames)\n",
    "\n",
    "# Get aligned frames\n",
    "aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "# Validate that both frames are valid\n",
    "if not aligned_depth_frame or not color_frame:\n",
    "    pass\n",
    "\n",
    "\n",
    "depth_intrinsics = rs.video_stream_profile(aligned_depth_frame.profile).get_intrinsics()\n",
    "\n",
    "depth_image = np.asarray(aligned_depth_frame.get_data())\n",
    "color_image = np.asarray(color_frame.get_data())\n",
    "\n",
    "pc.map_to(color_frame)\n",
    "points = pc.calculate(aligned_depth_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = points.get_vertices(), points.get_texture_coordinates()\n",
    "verts = np.asanyarray(v).view(np.float32).reshape(480, 640, 3)  # xyz\n",
    "texcoords = np.asanyarray(t).view(np.float32).reshape(480, 640, 2)  # uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "# I will link the notebook in the description\n",
    "# You can copy the class names from the description\n",
    "# or the notebook\n",
    "len(COCO_INSTANCE_CATEGORY_NAMES) # 91 classes including background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img, threshold=0.5):\n",
    "  transform = T.Compose([T.ToTensor()]) # Turn the image into a torch.tensor\n",
    "  img = transform(img)\n",
    "  # img = img.cuda() # Only if GPU, otherwise comment this line\n",
    "  pred = model([img]) # Send the image to the model. This runs on CPU, so its going to take time\n",
    "  #Let's change it to GPU\n",
    "  # pred = pred.cpu() # We will just send predictions back to CPU\n",
    "  # Now we need to extract the bounding boxes and masks\n",
    "  pred_score = list(pred[0]['scores'].detach().cpu().numpy())\n",
    "  pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]\n",
    "  masks = (pred[0]['masks'] > 0.5).squeeze().detach().cpu().numpy()\n",
    "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].cpu().numpy())]\n",
    "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().cpu().numpy())]\n",
    "  masks = masks[:pred_t+1]\n",
    "  pred_boxes = pred_boxes[:pred_t+1]\n",
    "  pred_class = pred_class[:pred_t+1]\n",
    "  return masks, pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating random color for the masks\n",
    "\n",
    "import random\n",
    "\n",
    "def random_color_masks(image):\n",
    "  # I will copy a list of colors here\n",
    "  colors = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180], [250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
    "  r = np.zeros_like(image).astype(np.uint8)\n",
    "  g = np.zeros_like(image).astype(np.uint8)\n",
    "  b = np.zeros_like(image).astype(np.uint8)\n",
    "  r[image==1], g[image==1], b[image==1] = colors[random.randrange(0, 10)]\n",
    "  colored_mask = np.stack([r,g,b], axis=2)\n",
    "  return colored_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_segmentation(img, threshold=0.5, rect_th=3,\n",
    "                          text_size=1, text_th=1, url=False):\n",
    "  masks, boxes, pred_cls = get_prediction(img, threshold=threshold)\n",
    "    \n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # For working with RGB images instead of BGR\n",
    "  for i in range(len(masks)):\n",
    "    rgb_mask = random_color_masks(masks[i])\n",
    "    img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)\n",
    "    pt1 = tuple(int(x) for x in boxes[i][0])\n",
    "    pt2 = tuple(int(x) for x in boxes[i][1])\n",
    "    cv2.rectangle(img, pt1, pt2, color=(0, 255, 0), thickness=rect_th)\n",
    "    cv2.putText(img, pred_cls[i], pt1, cv2.FONT_HERSHEY_SIMPLEX, text_size, (0, 255, 0), thickness=text_th)\n",
    "  return img, pred_cls, masks, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, pred_classes, masks, boxes = instance_segmentation(color_image, rect_th=1, text_th=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the predicted classes\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dim_high(points, dim):\n",
    "    if len(points.shape) ==3:\n",
    "        tmp = points[:,:,dim].flatten()\n",
    "    elif len(points.shape) ==2:\n",
    "        tmp = points[:,dim].flatten()\n",
    "    tmp = tmp[tmp!=0.0]\n",
    "    tmp = np.sort(tmp)\n",
    "    n = tmp[::-1]\n",
    "    n_bottom = n[0:10].mean()\n",
    "    return n_bottom\n",
    "\n",
    "def get_dim_low(points, dim):\n",
    "    if len(points.shape) ==3:\n",
    "        tmp = points[:,:,dim].flatten()\n",
    "    elif len(points.shape) ==2:\n",
    "        tmp = points[:,dim].flatten()\n",
    "    tmp = tmp[tmp!=0.0]\n",
    "    tmp = np.sort(tmp)\n",
    "    n_top = tmp[0:10].mean()\n",
    "    return n_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds(points):\n",
    "    \n",
    "    x_l = get_dim_low(points,0)\n",
    "    y_l = get_dim_low(points,1)\n",
    "    z_l = get_dim_low(points,2)\n",
    "    x_h = get_dim_high(points,0)\n",
    "    y_h = get_dim_high(points,1)\n",
    "    z_h = get_dim_high(points,2)\n",
    "    return x_l, y_l, z_l, x_h, y_h, z_h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points = verts[masks[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l, y_l, z_l, x_h, y_h, z_h = get_bounds(img_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = depth_intrinsics\n",
    "\n",
    "# pt000 = np.array([x_l, y_l, z_l])\n",
    "# pt001 = np.array([x_l, y_l, z_h])\n",
    "# pt010 = np.array([x_l, y_h, z_l])\n",
    "# pt011 = np.array([x_l, y_h, z_h])\n",
    "# pt100 = np.array([x_h, y_l, z_h])\n",
    "# pt101 = np.array([x_h, y_h, z_l])\n",
    "# pt110 = np.array([x_h, y_h, z_l])\n",
    "# pt111 = np.array([x_h, y_h, z_h])\n",
    "\n",
    "pt000 = np.array([x_l, y_l, z_l])\n",
    "pt100 = np.array([x_l, y_l, z_h])\n",
    "pt010 = np.array([x_l, y_h, z_l])\n",
    "pt110 = np.array([x_l, y_h, z_h])\n",
    "pt001 = np.array([x_h, y_l, z_l])\n",
    "pt101 = np.array([x_h, y_l, z_h])\n",
    "pt011 = np.array([x_h, y_h, z_l])\n",
    "pt111 = np.array([x_h, y_h, z_h])\n",
    "\n",
    "pixel000 = rs.rs2_project_point_to_pixel(intrinsics,pt000)\n",
    "pixel001 = rs.rs2_project_point_to_pixel(intrinsics,pt001)\n",
    "pixel010 = rs.rs2_project_point_to_pixel(intrinsics,pt010)\n",
    "pixel011 = rs.rs2_project_point_to_pixel(intrinsics,pt011)\n",
    "pixel100 = rs.rs2_project_point_to_pixel(intrinsics,pt100)\n",
    "pixel101 = rs.rs2_project_point_to_pixel(intrinsics,pt101)\n",
    "pixel110 = rs.rs2_project_point_to_pixel(intrinsics,pt110)\n",
    "pixel111 = rs.rs2_project_point_to_pixel(intrinsics,pt111)\n",
    "\n",
    "pixel000 = int(pixel000[0]) , int(pixel000[1])\n",
    "pixel001 = int(pixel001[0]) , int(pixel001[1])\n",
    "pixel010 = int(pixel010[0]) , int(pixel010[1])\n",
    "pixel011 = int(pixel011[0]) , int(pixel011[1])\n",
    "pixel100 = int(pixel100[0]) , int(pixel100[1])\n",
    "pixel101 = int(pixel101[0]) , int(pixel101[1])\n",
    "pixel110 = int(pixel110[0]) , int(pixel110[1])\n",
    "pixel111 = int(pixel111[0]) , int(pixel111[1])\n",
    "\n",
    "image_with_line = img.copy()\n",
    "image_with_line = cv2.line(image_with_line,pixel000,pixel001,(0,255,255))\n",
    "image_with_line = cv2.line(image_with_line,pixel000,pixel010,(0,255,255))\n",
    "image_with_line = cv2.line(image_with_line,pixel011,pixel001,(0,255,255))\n",
    "image_with_line = cv2.line(image_with_line,pixel011,pixel010,(0,255,255))\n",
    "\n",
    "image_with_line = cv2.line(image_with_line,pixel100,pixel101,(255,0,255))\n",
    "image_with_line = cv2.line(image_with_line,pixel100,pixel110,(255,0,255))\n",
    "image_with_line = cv2.line(image_with_line,pixel111,pixel101,(255,0,255))\n",
    "image_with_line = cv2.line(image_with_line,pixel111,pixel110,(255,0,255))\n",
    "\n",
    "image_with_line = cv2.line(image_with_line,pixel000,pixel100,(255,255,0))\n",
    "image_with_line = cv2.line(image_with_line,pixel001,pixel101,(255,255,0))\n",
    "image_with_line = cv2.line(image_with_line,pixel010,pixel110,(255,255,0))\n",
    "image_with_line = cv2.line(image_with_line,pixel011,pixel111,(255,255,0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pixel000)\n",
    "print(pixel001)\n",
    "print(pixel010)\n",
    "print(pixel011)\n",
    "print(pixel100)\n",
    "print(pixel101)\n",
    "print(pixel110)\n",
    "print(pixel111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_with_line = cv2.line(img,pixel000,pixel100,(255,255,255))\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_with_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_from_bounds(img_out, intrin, x_l, y_l, z_l, x_h, y_h, z_h):\n",
    "    pt000 = np.array(x_l, y_l, z_l)\n",
    "    pt001 = np.array(x_l, y_l, z_h)\n",
    "    pt010 = np.array(x_l, y_h, z_l)\n",
    "    pt011 = np.array(x_l, y_h, z_h)\n",
    "    pt100 = np.array(x_h, y_l, z_h)\n",
    "    pt101 = np.array(x_h, y_h, z_l)\n",
    "    pt110 = np.array(x_h, y_h, z_l)\n",
    "    pt111 = np.array(x_h, y_h, z_h)\n",
    "\n",
    "    pixel000 = rs.rs2_project_point_to_pixel(intrin,pt000)\n",
    "    pixel001 = rs.rs2_project_point_to_pixel(intrin,pt001)\n",
    "    pixel010 = rs.rs2_project_point_to_pixel(intrin,pt010)\n",
    "    pixel011 = rs.rs2_project_point_to_pixel(intrin,pt011)\n",
    "    pixel100 = rs.rs2_project_point_to_pixel(intrin,pt100)\n",
    "    pixel101 = rs.rs2_project_point_to_pixel(intrin,pt101)\n",
    "    pixel110 = rs.rs2_project_point_to_pixel(intrin,pt110)\n",
    "    pixel111 = rs.rs2_project_point_to_pixel(intrin,pt111)\n",
    "\n",
    "    # draw 12 lines of the cubes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X: {x_l} {x_h}')\n",
    "print(f'Y: {y_l} {y_h}')\n",
    "print(f'Z: {z_l} {z_h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X:  {x_h - x_l}')\n",
    "print(f'Y:  {y_h - y_l}')\n",
    "print(f'Z:  {z_h - z_l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points = verts[masks[0],:]pc.map_to(color_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points.shape()\n",
    "\n",
    "rs.rs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_z_top(img_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points[:,2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
